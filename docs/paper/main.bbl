% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.0 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{none/global//global/global}
    \entry{Miyao}{article}{}
      \name{author}{3}{}{%
        {{hash=29f7b66d59c80dd0b2cb51553bf038f1}{%
           family={Miyao},
           familyi={M\bibinitperiod},
           given={Tomoyuki},
           giveni={T\bibinitperiod}}}%
        {{hash=bcf42905f3ab298a67cd93d4a07d1f13}{%
           family={Kaneko},
           familyi={K\bibinitperiod},
           given={Hiromasa},
           giveni={H\bibinitperiod}}}%
        {{hash=6769f70fe09f2aff1baab263a4047012}{%
           family={Funatsu},
           familyi={F\bibinitperiod},
           given={Kimito},
           giveni={K\bibinitperiod}}}%
      }
      \strng{namehash}{2166784888d410731f5a9375279856eb}
      \strng{fullhash}{7d0176e552e677f28b9e0d94bc4c6c62}
      \strng{bibnamehash}{7d0176e552e677f28b9e0d94bc4c6c62}
      \strng{authorbibnamehash}{7d0176e552e677f28b9e0d94bc4c6c62}
      \strng{authornamehash}{2166784888d410731f5a9375279856eb}
      \strng{authorfullhash}{7d0176e552e677f28b9e0d94bc4c6c62}
      \field{extraname}{1}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Retrieving descriptor information (x information) from a value of an objective variable (y) is a fundamental problem in inverse quantitative structure--property relationship (inverse-QSPR) analysis but challenging because of the complexity of the preimage function. Herewith, we propose using a cluster-wise multiple linear regression (cMLR) model as a QSPR model for inverse-QSPR analysis. x information is acquired as a probability density function by combining cMLR and the prior distribution modeled with a mixture of Gaussians (GMMs). Three case studies were conducted to demonstrate various aspects of the potential of cMLR. It was found that the predictive power of cMLR was superior to that of MLR, especially for data with nonlinearity. Moreover, it turned out that the applicability domain could be considered since the posterior distribution inherits the prior distribution's feature (i.e., training data feature) and represents the possibility of having the desired property. Finally, a series of inverse anal...}
      \field{issn}{15205142}
      \field{journaltitle}{J. Chem. Inf. Model.}
      \field{number}{2}
      \field{title}{{Inverse QSPR/QSAR Analysis for Chemical Structure Generation (from y to x)}}
      \field{volume}{56}
      \field{year}{2016}
      \field{pages}{286\bibrangedash 299}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1021/acs.jcim.5b00628
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Miyao, Kaneko, Funatsu - Unknown - Inverse QSPRQSAR Analysis for Chemical Structure Generation (from y to x).pdf:pdf
      \endverb
      \verb{urlraw}
      \verb https://gateway.itc.u-tokyo.ac.jp:11030/doi/pdfplus/10.1021/acs.jcim.5b00628
      \endverb
      \verb{url}
      \verb https://gateway.itc.u-tokyo.ac.jp:11030/doi/pdfplus/10.1021/acs.jcim.5b00628
      \endverb
    \endentry
    \entry{Miyao2017}{article}{}
      \name{author}{3}{}{%
        {{hash=29f7b66d59c80dd0b2cb51553bf038f1}{%
           family={Miyao},
           familyi={M\bibinitperiod},
           given={Tomoyuki},
           giveni={T\bibinitperiod}}}%
        {{hash=6769f70fe09f2aff1baab263a4047012}{%
           family={Funatsu},
           familyi={F\bibinitperiod},
           given={Kimito},
           giveni={K\bibinitperiod}}}%
        {{hash=47a4bbea95808ce55fc26d9535990987}{%
           family={Bajorath},
           familyi={B\bibinitperiod},
           given={J{\"{u}}rgen},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{2166784888d410731f5a9375279856eb}
      \strng{fullhash}{ccad34dbcb6ac4ccf992b538f2eb2c02}
      \strng{bibnamehash}{ccad34dbcb6ac4ccf992b538f2eb2c02}
      \strng{authorbibnamehash}{ccad34dbcb6ac4ccf992b538f2eb2c02}
      \strng{authornamehash}{2166784888d410731f5a9375279856eb}
      \strng{authorfullhash}{ccad34dbcb6ac4ccf992b538f2eb2c02}
      \field{extraname}{2}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{F1000Research}
      \field{month}{7}
      \field{title}{{Exploring differential evolution for inverse QSAR analysis}}
      \field{volume}{6}
      \field{year}{2017}
      \field{pages}{1285}
      \range{pages}{1}
      \verb{doi}
      \verb 10.12688/f1000research.12228.1
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Miyao, Funatsu, Bajorath - 2017 - Exploring differential evolution for inverse QSAR analysis.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb https://f1000research.com/articles/6-1285/v1
      \endverb
      \verb{url}
      \verb https://f1000research.com/articles/6-1285/v1
      \endverb
      \keyw{drug,inverse-QSAR}
    \endentry
    \entry{Kingma2014}{article}{}
      \name{author}{4}{}{%
        {{hash=b6fbd171848aad4edf3925543f1f1522}{%
           family={Kingma},
           familyi={K\bibinitperiod},
           given={Diederik\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=a0de5b19c734d1fa5491ea6ab13715a7}{%
           family={Rezende},
           familyi={R\bibinitperiod},
           given={Danilo\bibnamedelima J.},
           giveni={D\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=b520f2e46ec8803dd4c66bf1d6059482}{%
           family={Mohamed},
           familyi={M\bibinitperiod},
           given={Shakir},
           giveni={S\bibinitperiod}}}%
        {{hash=53d2880ad8047b61cdae2c6b2803e763}{%
           family={Welling},
           familyi={W\bibinitperiod},
           given={Max},
           giveni={M\bibinitperiod}}}%
      }
      \strng{namehash}{0018e09b9f142d15c9693e18a17bdf3f}
      \strng{fullhash}{7db08568758faaf87fe42d6906a6bb32}
      \strng{bibnamehash}{7db08568758faaf87fe42d6906a6bb32}
      \strng{authorbibnamehash}{7db08568758faaf87fe42d6906a6bb32}
      \strng{authornamehash}{0018e09b9f142d15c9693e18a17bdf3f}
      \strng{authorfullhash}{7db08568758faaf87fe42d6906a6bb32}
      \field{sortinit}{3}
      \field{sortinithash}{a4b52e5432884761f50fb9571273b93e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning.}
      \field{eprinttype}{arXiv}
      \field{issn}{10495258}
      \field{journaltitle}{arXiv.org}
      \field{month}{6}
      \field{title}{{Semi-Supervised Learning with Deep Generative Models}}
      \field{volume}{cs.LG}
      \field{year}{2014}
      \field{pages}{1\bibrangedash 9}
      \range{pages}{9}
      \verb{eprint}
      \verb 1406.5298
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Kingma et al. - 2014 - Semi-Supervised Learning with Deep Generative Models(2).pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1406.5298
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1406.5298
      \endverb
      \keyw{VAE}
    \endentry
    \entry{Doersch2016}{article}{}
      \name{author}{1}{}{%
        {{hash=96b67cea31d7dd5c10af974faba91947}{%
           family={Doersch},
           familyi={D\bibinitperiod},
           given={Carl},
           giveni={C\bibinitperiod}}}%
      }
      \strng{namehash}{96b67cea31d7dd5c10af974faba91947}
      \strng{fullhash}{96b67cea31d7dd5c10af974faba91947}
      \strng{bibnamehash}{96b67cea31d7dd5c10af974faba91947}
      \strng{authorbibnamehash}{96b67cea31d7dd5c10af974faba91947}
      \strng{authornamehash}{96b67cea31d7dd5c10af974faba91947}
      \strng{authorfullhash}{96b67cea31d7dd5c10af974faba91947}
      \field{sortinit}{3}
      \field{sortinithash}{a4b52e5432884761f50fb9571273b93e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{arXiv.org}
      \field{month}{6}
      \field{title}{{Tutorial on Variational Autoencoders}}
      \field{year}{2016}
      \verb{eprint}
      \verb 1606.05908
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Doersch - 2016 - Tutorial on Variational Autoencoders.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1606.05908
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1606.05908
      \endverb
    \endentry
    \entry{Gomez-Bombarelli2016}{article}{}
      \name{author}{10}{}{%
        {{hash=a37688f976e048ffbc85a45699635c91}{%
           family={G{\'{o}}mez-Bombarelli},
           familyi={G\bibinithyphendelim B\bibinitperiod},
           given={Rafael},
           giveni={R\bibinitperiod}}}%
        {{hash=8ddf752562b01a466863a7cfbec68eee}{%
           family={Wei},
           familyi={W\bibinitperiod},
           given={Jennifer\bibnamedelima N.},
           giveni={J\bibinitperiod\bibinitdelim N\bibinitperiod}}}%
        {{hash=834f50f5d5a332c21effd10f07daf79e}{%
           family={Duvenaud},
           familyi={D\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=48ac403ef8899f30cccb37d29c0c96a7}{%
           family={Hern{\'{a}}ndez-Lobato},
           familyi={H\bibinithyphendelim L\bibinitperiod},
           given={Jos{\'{e}}\bibnamedelima Miguel},
           giveni={J\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=a030eefab0eb24c118787aac9c45ff0d}{%
           family={S{\'{a}}nchez-Lengeling},
           familyi={S\bibinithyphendelim L\bibinitperiod},
           given={Benjam{\'{\i}}n},
           giveni={B\bibinitperiod}}}%
        {{hash=9bb1c5a7defe64b1b9a468f677e16937}{%
           family={Sheberla},
           familyi={S\bibinitperiod},
           given={Dennis},
           giveni={D\bibinitperiod}}}%
        {{hash=5debbaca3d1169a9867a72e085c3cefd}{%
           family={Aguilera-Iparraguirre},
           familyi={A\bibinithyphendelim I\bibinitperiod},
           given={Jorge},
           giveni={J\bibinitperiod}}}%
        {{hash=24d74bea68cfb85c9da12548d0141d35}{%
           family={Hirzel},
           familyi={H\bibinitperiod},
           given={Timothy\bibnamedelima D.},
           giveni={T\bibinitperiod\bibinitdelim D\bibinitperiod}}}%
        {{hash=c1552be0c6aa9c6e0fd91a130a682853}{%
           family={Adams},
           familyi={A\bibinitperiod},
           given={Ryan\bibnamedelima P.},
           giveni={R\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=083dcdd0db2687433b22fabfb2e55c17}{%
           family={Aspuru-Guzik},
           familyi={A\bibinithyphendelim G\bibinitperiod},
           given={Al{\'{a}}n},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{4e0c037003563f7fd8f3562cc4d1d703}
      \strng{fullhash}{5ec80736eac7b30076995115d9580a22}
      \strng{bibnamehash}{4e0c037003563f7fd8f3562cc4d1d703}
      \strng{authorbibnamehash}{4e0c037003563f7fd8f3562cc4d1d703}
      \strng{authornamehash}{4e0c037003563f7fd8f3562cc4d1d703}
      \strng{authorfullhash}{5ec80736eac7b30076995115d9580a22}
      \field{sortinit}{4}
      \field{sortinithash}{11cdaee3b18e01d77f3f428b13c1fc76}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We report a method to convert discrete representations of molecules to and from a multidimensional continuous representation. This model allows us to generate new molecules for efficient exploration and optimization through open-ended spaces of chemical compounds. A deep neural network was trained on hundreds of thousands of existing chemical structures to construct three coupled functions: an encoder, a decoder and a predictor. The encoder converts the discrete representation of a molecule into a real-valued continuous vector, and the decoder converts these continuous vectors back to discrete molecular representations. The predictor estimates chemical properties from the latent continuous vector representation of the molecule. Continuous representations allow us to automatically generate novel chemical structures by performing simple operations in the latent space, such as decoding random vectors, perturbing known chemical structures, or interpolating between molecules. Continuous representations also allow the use of powerful gradient-based optimization to efficiently guide the search for optimized functional compounds. We demonstrate our method in the domain of drug-like molecules and also in the set of molecules with fewer that nine heavy atoms.}
      \field{eprinttype}{arXiv}
      \field{issn}{2374-7943}
      \field{journaltitle}{ACS Cent. Sci.}
      \field{month}{2}
      \field{number}{2}
      \field{title}{{Automatic Chemical Design Using a Data-Driven Continuous Representation of Molecules}}
      \field{volume}{4}
      \field{year}{2018}
      \field{pages}{268\bibrangedash 276}
      \range{pages}{9}
      \verb{doi}
      \verb 10.1021/acscentsci.7b00572
      \endverb
      \verb{eprint}
      \verb 1610.02415
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/G{\'{o}}mez-Bombarelli et al. - 2016 - Automatic chemical design using a data-driven continuous representation of molecules.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1610.02415 http://pubs.acs.org/doi/10.1021/acscentsci.7b00572
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1610.02415%20http://pubs.acs.org/doi/10.1021/acscentsci.7b00572
      \endverb
      \keyw{drug}
    \endentry
    \entry{aae}{article}{}
      \name{author}{5}{}{%
        {{hash=9d8b4e8b7224f41ba985f7dbc8896258}{%
           family={Makhzani},
           familyi={M\bibinitperiod},
           given={Alireza},
           giveni={A\bibinitperiod}}}%
        {{hash=8f128e70084608a2c29c497ebd794f87}{%
           family={Shlens},
           familyi={S\bibinitperiod},
           given={Jonathon},
           giveni={J\bibinitperiod}}}%
        {{hash=5a9f30e0c0441d2aea255916ff375e8c}{%
           family={Jaitly},
           familyi={J\bibinitperiod},
           given={Navdeep},
           giveni={N\bibinitperiod}}}%
        {{hash=5d2585c11210cf1d4512e6e0a03ec315}{%
           family={Goodfellow},
           familyi={G\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod}}}%
        {{hash=05ffdac2d7284157b135cbb85f33e686}{%
           family={Frey},
           familyi={F\bibinitperiod},
           given={Brendan},
           giveni={B\bibinitperiod}}}%
      }
      \strng{namehash}{eacc11de2ad90792934b4f1b2f2f417b}
      \strng{fullhash}{26991a4c213cb45d5a382fb715153564}
      \strng{bibnamehash}{26991a4c213cb45d5a382fb715153564}
      \strng{authorbibnamehash}{26991a4c213cb45d5a382fb715153564}
      \strng{authornamehash}{eacc11de2ad90792934b4f1b2f2f417b}
      \strng{authorfullhash}{26991a4c213cb45d5a382fb715153564}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we propose the "adversarial autoencoder" (AAE), which is a probabilistic autoencoder that uses the recently proposed generative adversarial networks (GAN) to perform variational inference by matching the aggregated posterior of the hidden code vector of the autoencoder with an arbitrary prior distribution. Matching the aggregated posterior to the prior ensures that generating from any part of prior space results in meaningful samples. As a result, the decoder of the adversarial autoencoder learns a deep generative model that maps the imposed prior to the data distribution. We show how the adversarial autoencoder can be used in applications such as semi-supervised classification, disentangling style and content of images, unsupervised clustering, dimensionality reduction and data visualization. We performed experiments on MNIST, Street View House Numbers and Toronto Face datasets and show that adversarial autoencoders achieve competitive results in generative modeling and semi-supervised classification tasks.}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{arXiv.org}
      \field{month}{11}
      \field{title}{{Adversarial Autoencoders}}
      \field{year}{2015}
      \verb{eprint}
      \verb 1511.05644
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Makhzani et al. - 2015 - Adversarial Autoencoders.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1511.05644
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1511.05644
      \endverb
    \endentry
    \entry{Blaschke2018}{article}{}
      \name{author}{5}{}{%
        {{hash=e52e987849436cae55c3929da2203ba4}{%
           family={Blaschke},
           familyi={B\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=02d28c1cf3482d4e2af59f31a7ab3e88}{%
           family={Olivecrona},
           familyi={O\bibinitperiod},
           given={Marcus},
           giveni={M\bibinitperiod}}}%
        {{hash=07fc5197917d83cd3df96202400b36bc}{%
           family={Engkvist},
           familyi={E\bibinitperiod},
           given={Ola},
           giveni={O\bibinitperiod}}}%
        {{hash=47a4bbea95808ce55fc26d9535990987}{%
           family={Bajorath},
           familyi={B\bibinitperiod},
           given={J{\"{u}}rgen},
           giveni={J\bibinitperiod}}}%
        {{hash=52c3e5a8c2ccdc7c6f2b529db69f6872}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Hongming},
           giveni={H\bibinitperiod}}}%
      }
      \strng{namehash}{94fab34a9aa11fe0ab1f02c96bce1b4f}
      \strng{fullhash}{07c72c035f87f860b3a9dc2d00f6141e}
      \strng{bibnamehash}{07c72c035f87f860b3a9dc2d00f6141e}
      \strng{authorbibnamehash}{07c72c035f87f860b3a9dc2d00f6141e}
      \strng{authornamehash}{94fab34a9aa11fe0ab1f02c96bce1b4f}
      \strng{authorfullhash}{07c72c035f87f860b3a9dc2d00f6141e}
      \field{sortinit}{6}
      \field{sortinithash}{57e57fb8451e7fcfa45d1e069f6d3136}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A major challenge in computational chemistry is the generation of novel molecular structures with desirable pharmacological and physiochemical properties. In this work, we investigate the potential use of autoencoder, a deep learning methodology, for de novo molecular design. Various generative autoencoders were used to map molecule structures into a continuous latent space and vice versa and their performance as structure generator was assessed. Our results show that the latent space preserves chemical similarity principle and thus can be used for the generation of analogue structures. Furthermore, the latent space created by autoencoders were searched systematically to generate novel compounds with predicted activity against dopamine receptor type 2 and compounds similar to known active compounds not included in the trainings set were identified.}
      \field{eprinttype}{arXiv}
      \field{issn}{1868-1751}
      \field{journaltitle}{Mol. Inform.}
      \field{month}{1}
      \field{number}{1-2}
      \field{title}{{Application of Generative Autoencoder in De Novo Molecular Design}}
      \field{volume}{37}
      \field{year}{2018}
      \field{pages}{1700123}
      \range{pages}{1}
      \verb{doi}
      \verb 10.1002/minf.201700123
      \endverb
      \verb{eprint}
      \verb 1711.07839
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Blaschke et al. - 2018 - Application of Generative Autoencoder in De Novo Molecular Design.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://doi.wiley.com/10.1002/minf.201700123 http://www.ncbi.nlm.nih.gov/pubmed/29235269 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5836887
      \endverb
      \verb{url}
      \verb http://doi.wiley.com/10.1002/minf.201700123%20http://www.ncbi.nlm.nih.gov/pubmed/29235269%20http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5836887
      \endverb
      \keyw{Autoencoder,chemoinformatics,de novo molecular design,deep learning,drug,inverse QSAR}
    \endentry
    \entry{pugan}{article}{}
      \name{author}{4}{}{%
        {{hash=6c8bb3e62bdb45979a53e9a7fb57125f}{%
           family={Hou},
           familyi={H\bibinitperiod},
           given={Ming},
           giveni={M\bibinitperiod}}}%
        {{hash=ba7c953c3be94796c2020df8a7b60ecb}{%
           family={Chaib-Draa},
           familyi={C\bibinithyphendelim D\bibinitperiod},
           given={Brahim},
           giveni={B\bibinitperiod}}}%
        {{hash=ad699cc0ff44aa8ef2a872dab8e20175}{%
           family={Li},
           familyi={L\bibinitperiod},
           given={Chao},
           giveni={C\bibinitperiod}}}%
        {{hash=8a239bd07f908087a20dfcf87572e035}{%
           family={Zhao},
           familyi={Z\bibinitperiod},
           given={Qibin},
           giveni={Q\bibinitperiod}}}%
      }
      \strng{namehash}{528a3cb463eb45fc80441d1576a85923}
      \strng{fullhash}{46e637c901d6cddbfacce82a3cb8ba6c}
      \strng{bibnamehash}{46e637c901d6cddbfacce82a3cb8ba6c}
      \strng{authorbibnamehash}{46e637c901d6cddbfacce82a3cb8ba6c}
      \strng{authornamehash}{528a3cb463eb45fc80441d1576a85923}
      \strng{authorfullhash}{46e637c901d6cddbfacce82a3cb8ba6c}
      \field{sortinit}{9}
      \field{sortinithash}{1dd72ab054147731c9d824b49aba0534}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this work, we consider the task of classifying binary positive-unlabeled (PU) data. The existing discriminative learning based PU models attempt to seek an optimal reweighting strategy for U data, so that a decent decision boundary can be found. However, given limited P data, the conventional PU models tend to suffer from overfitting when adapted to very flexible deep neural networks. In contrast, we are the first to innovate a totally new paradigm to attack the binary PU task, from perspective of generative learning by leveraging the powerful generative adversarial networks (GAN). Our generative positive-unlabeled (GenPU) framework incorporates an array of discriminators and generators that are endowed with different roles in simultaneously producing positive and negative realistic samples. We provide theoretical analysis to justify that, at equilibrium, GenPU is capable of recovering both positive and negative data distributions. Moreover, we show GenPU is generalizable and closely related to the semi-supervised classification. Given rather limited P data, experiments on both synthetic and real-world dataset demonstrate the effectiveness of our proposed framework. With infinite realistic and diverse sample streams generated from GenPU, a very flexible classifier can then be trained using deep neural networks.}
      \field{eprinttype}{arXiv}
      \field{title}{{Generative Adversarial Positive-Unlabelled Learning}}
      \verb{eprint}
      \verb arXiv:1711.08054v2
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Hou et al. - Unknown - Generative Adversarial Positive-Unlabelled Learning.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb https://arxiv.org/pdf/1711.08054.pdf
      \endverb
      \verb{url}
      \verb https://arxiv.org/pdf/1711.08054.pdf
      \endverb
    \endentry
    \entry{backpropagation}{article}{}
      \name{author}{3}{}{%
        {{hash=026532b517837608b51c6a36bc4a3b5d}{%
           family={Rumelhart},
           familyi={R\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=9a8750ccdb2a4cf14d2655face1ce016}{%
           family={Hinton},
           familyi={H\bibinitperiod},
           given={Geoffrey},
           giveni={G\bibinitperiod}}}%
        {{hash=9a6ddff57425ea6844469bed847179bc}{%
           family={Williams},
           familyi={W\bibinitperiod},
           given={Ronald},
           giveni={R\bibinitperiod}}}%
      }
      \strng{namehash}{ada51d45274d6232acdb9afc0fd0505c}
      \strng{fullhash}{2b6f66f3b7ba9dfff732e1876f7676b6}
      \strng{bibnamehash}{2b6f66f3b7ba9dfff732e1876f7676b6}
      \strng{authorbibnamehash}{2b6f66f3b7ba9dfff732e1876f7676b6}
      \strng{authornamehash}{ada51d45274d6232acdb9afc0fd0505c}
      \strng{authorfullhash}{2b6f66f3b7ba9dfff732e1876f7676b6}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0028-0836}
      \field{journaltitle}{Nature}
      \field{number}{6088}
      \field{title}{{Learning representations by back-propagating errors}}
      \field{volume}{323}
      \field{year}{1986}
      \field{pages}{533\bibrangedash 536}
      \range{pages}{4}
      \verb{doi}
      \verb 10.1038/323533a0
      \endverb
      \verb{urlraw}
      \verb http://www.nature.com/doifinder/10.1038/323533a0
      \endverb
      \verb{url}
      \verb http://www.nature.com/doifinder/10.1038/323533a0
      \endverb
    \endentry
    \entry{adagrad}{article}{}
      \name{author}{3}{}{%
        {{hash=dfdc73b1460e57f1e6231087904f53da}{%
           family={{C. Duchi}},
           familyi={C\bibinitperiod},
           given={John},
           giveni={J\bibinitperiod}}}%
        {{hash=0b3d32703edd2b7248e8e8f33c5893db}{%
           family={Hazan},
           familyi={H\bibinitperiod},
           given={Elad},
           giveni={E\bibinitperiod}}}%
        {{hash=300d4990e626d975e0c28630444f63c3}{%
           family={Singer},
           familyi={S\bibinitperiod},
           given={Yoram},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{010f31bcbf6c40bbba750bafb0bf3cf9}
      \strng{fullhash}{2d92bb21d2042a57e49214f4db6ea72e}
      \strng{bibnamehash}{2d92bb21d2042a57e49214f4db6ea72e}
      \strng{authorbibnamehash}{2d92bb21d2042a57e49214f4db6ea72e}
      \strng{authornamehash}{010f31bcbf6c40bbba750bafb0bf3cf9}
      \strng{authorfullhash}{2d92bb21d2042a57e49214f4db6ea72e}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{J. Mach. Learn. Res.}
      \field{title}{{Adaptive Subgradient Methods for Online Learning and Stochastic Optimization}}
      \field{volume}{12}
      \field{year}{2011}
      \field{pages}{2121\bibrangedash 2159}
      \range{pages}{39}
    \endentry
    \entry{adam}{article}{}
      \name{author}{2}{}{%
        {{hash=b6fbd171848aad4edf3925543f1f1522}{%
           family={Kingma},
           familyi={K\bibinitperiod},
           given={Diederik\bibnamedelima P.},
           giveni={D\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=8aa66e8231cc2fdbe67aa4f18ca970c6}{%
           family={Ba},
           familyi={B\bibinitperiod},
           given={Jimmy},
           giveni={J\bibinitperiod}}}%
      }
      \strng{namehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{fullhash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{bibnamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authorbibnamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authornamehash}{a09df9f123146b8e2c7f1134c9496932}
      \strng{authorfullhash}{a09df9f123146b8e2c7f1134c9496932}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce Adam, an algorithm for first-order gradient-based optimization of stochastic objective functions, based on adaptive estimates of lower-order moments. The method is straightforward to implement, is computationally efficient, has little memory requirements, is invariant to diagonal rescaling of the gradients, and is well suited for problems that are large in terms of data and/or parameters. The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients. The hyper-parameters have intuitive interpretations and typically require little tuning. Some connections to related algorithms, on which Adam was inspired, are discussed. We also analyze the theoretical convergence properties of the algorithm and provide a regret bound on the convergence rate that is comparable to the best known results under the online convex optimization framework. Empirical results demonstrate that Adam works well in practice and compares favorably to other stochastic optimization methods. Finally, we discuss AdaMax, a variant of Adam based on the infinity norm.}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{arXiv.org}
      \field{month}{12}
      \field{title}{{Adam: A Method for Stochastic Optimization}}
      \field{year}{2014}
      \verb{eprint}
      \verb 1412.6980
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1412.6980
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1412.6980
      \endverb
    \endentry
    \entry{relu}{article}{}
      \name{author}{1}{}{%
        {{hash=2c4405bb4d2538bf5d9caa79e5c103f0}{%
           family={Agarap},
           familyi={A\bibinitperiod},
           given={Abien\bibnamedelima Fred},
           giveni={A\bibinitperiod\bibinitdelim F\bibinitperiod}}}%
      }
      \strng{namehash}{2c4405bb4d2538bf5d9caa79e5c103f0}
      \strng{fullhash}{2c4405bb4d2538bf5d9caa79e5c103f0}
      \strng{bibnamehash}{2c4405bb4d2538bf5d9caa79e5c103f0}
      \strng{authorbibnamehash}{2c4405bb4d2538bf5d9caa79e5c103f0}
      \strng{authornamehash}{2c4405bb4d2538bf5d9caa79e5c103f0}
      \strng{authorfullhash}{2c4405bb4d2538bf5d9caa79e5c103f0}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We introduce the use of rectified linear units (ReLU) as the classification function in a deep neural network (DNN). Conventionally, ReLU is used as an activation function in DNNs, with Softmax function as their classification function. However, there have been several studies on using a classification function other than Softmax, and this study is an addition to those. We accomplish this by taking the activation of the penultimate layer {\$}h{\_}{\{}n - 1{\}}{\$} in a neural network, then multiply it by weight parameters {\$}\backslashtheta{\$} to get the raw scores {\$}o{\_}{\{}i{\}}{\$}. Afterwards, we threshold the raw scores {\$}o{\_}{\{}i{\}}{\$} by {\$}0{\$}, i.e. {\$}f(o) = \backslashmax(0, o{\_}{\{}i{\}}){\$}, where {\$}f(o){\$} is the ReLU function. We provide class predictions {\$}\backslashhat{\{}y{\}}{\$} through argmax function, i.e. argmax {\$}f(x){\$}.}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{arXiv.org}
      \field{month}{3}
      \field{title}{{Deep Learning using Rectified Linear Units (ReLU)}}
      \field{year}{2018}
      \verb{eprint}
      \verb 1803.08375
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1803.08375
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1803.08375
      \endverb
    \endentry
    \entry{sigmoid}{incollection}{}
      \name{author}{2}{}{%
        {{hash=8efb16654df241d885e2e492a3eda10a}{%
           family={Han},
           familyi={H\bibinitperiod},
           given={Jun},
           giveni={J\bibinitperiod}}}%
        {{hash=206d698c619d92fe48294840e72ab1d0}{%
           family={Moraga},
           familyi={M\bibinitperiod},
           given={Claudio},
           giveni={C\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer, Berlin, Heidelberg}%
      }
      \strng{namehash}{a32b1b28e916d8432e9a526daeb0ed6e}
      \strng{fullhash}{a32b1b28e916d8432e9a526daeb0ed6e}
      \strng{bibnamehash}{a32b1b28e916d8432e9a526daeb0ed6e}
      \strng{authorbibnamehash}{a32b1b28e916d8432e9a526daeb0ed6e}
      \strng{authornamehash}{a32b1b28e916d8432e9a526daeb0ed6e}
      \strng{authorfullhash}{a32b1b28e916d8432e9a526daeb0ed6e}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{The influence of the sigmoid function parameters on the speed of backpropagation learning}}
      \field{year}{1995}
      \field{pages}{195\bibrangedash 201}
      \range{pages}{7}
      \verb{doi}
      \verb 10.1007/3-540-59497-3_175
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/3-540-59497-3{\_}175
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/3-540-59497-3%7B%5C_%7D175
      \endverb
    \endentry
    \entry{selu}{article}{}
      \name{author}{4}{}{%
        {{hash=dd69f2d35665eb16375f92c741a26393}{%
           family={Klambauer},
           familyi={K\bibinitperiod},
           given={G{\"{u}}nter},
           giveni={G\bibinitperiod}}}%
        {{hash=1a47640139e63b9b5969c969dfe95def}{%
           family={Unterthiner},
           familyi={U\bibinitperiod},
           given={Thomas},
           giveni={T\bibinitperiod}}}%
        {{hash=a9e3f196e64115d1eeaae340fd4142df}{%
           family={Mayr},
           familyi={M\bibinitperiod},
           given={Andreas},
           giveni={A\bibinitperiod}}}%
        {{hash=41b31e29fb2bdbf9f5c9c1b0d5b3e815}{%
           family={Hochreiter},
           familyi={H\bibinitperiod},
           given={Sepp},
           giveni={S\bibinitperiod}}}%
      }
      \strng{namehash}{f19a469e3a91612b2f412943b7a9dade}
      \strng{fullhash}{31fe53038d7ae48603f6d61911ecf772}
      \strng{bibnamehash}{31fe53038d7ae48603f6d61911ecf772}
      \strng{authorbibnamehash}{31fe53038d7ae48603f6d61911ecf772}
      \strng{authornamehash}{f19a469e3a91612b2f412943b7a9dade}
      \strng{authorfullhash}{31fe53038d7ae48603f6d61911ecf772}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Deep Learning has revolutionized vision via convolutional neural networks (CNNs) and natural language processing via recurrent neural networks (RNNs). However, success stories of Deep Learning with standard feed-forward neural networks (FNNs) are rare. FNNs that perform well are typically shallow and, therefore cannot exploit many levels of abstract representations. We introduce self-normalizing neural networks (SNNs) to enable high-level abstract representations. While batch normalization requires explicit normalization, neuron activations of SNNs automatically converge towards zero mean and unit variance. The activation function of SNNs are "scaled exponential linear units" (SELUs), which induce self-normalizing properties. Using the Banach fixed-point theorem, we prove that activations close to zero mean and unit variance that are propagated through many network layers will converge towards zero mean and unit variance -- even under the presence of noise and perturbations. This convergence property of SNNs allows to (1) train deep networks with many layers, (2) employ strong regularization, and (3) to make learning highly robust. Furthermore, for activations not close to unit variance, we prove an upper and lower bound on the variance, thus, vanishing and exploding gradients are impossible. We compared SNNs on (a) 121 tasks from the UCI machine learning repository, on (b) drug discovery benchmarks, and on (c) astronomy tasks with standard FNNs and other machine learning methods such as random forests and support vector machines. SNNs significantly outperformed all competing FNN methods at 121 UCI tasks, outperformed all competing methods at the Tox21 dataset, and set a new record at an astronomy data set. The winning SNN architectures are often very deep. Implementations are available at: github.com/bioinf-jku/SNNs.}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{arXiv.org}
      \field{month}{6}
      \field{title}{{Self-Normalizing Neural Networks}}
      \field{year}{2017}
      \verb{eprint}
      \verb 1706.02515
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Klambauer et al. - 2017 - Self-Normalizing Neural Networks.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1706.02515
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1706.02515
      \endverb
    \endentry
    \entry{gan}{article}{}
      \name{author}{8}{}{%
        {{hash=d4f74ef4c79f3bb1e51e378184d8850e}{%
           family={Goodfellow},
           familyi={G\bibinitperiod},
           given={Ian\bibnamedelima J.},
           giveni={I\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=a341d25f80a8118cdbb90b272adc8b4f}{%
           family={Pouget-Abadie},
           familyi={P\bibinithyphendelim A\bibinitperiod},
           given={Jean},
           giveni={J\bibinitperiod}}}%
        {{hash=9e80f4779b032f68a6106e1424345450}{%
           family={Mirza},
           familyi={M\bibinitperiod},
           given={Mehdi},
           giveni={M\bibinitperiod}}}%
        {{hash=743dd6cdaa6639320289d219d351d7b7}{%
           family={Xu},
           familyi={X\bibinitperiod},
           given={Bing},
           giveni={B\bibinitperiod}}}%
        {{hash=e8151f1b8f85a048cacb34f374ec922b}{%
           family={Warde-Farley},
           familyi={W\bibinithyphendelim F\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=9ca00ffd7cc35f7cfb8f698aa9239c76}{%
           family={Ozair},
           familyi={O\bibinitperiod},
           given={Sherjil},
           giveni={S\bibinitperiod}}}%
        {{hash=ccec1ccd2e1aa86960eb2e872c6b7020}{%
           family={Courville},
           familyi={C\bibinitperiod},
           given={Aaron},
           giveni={A\bibinitperiod}}}%
        {{hash=40a8e4774982146adc2688546f54efb2}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Yoshua},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{8b5c7065f4df4f81627df9460343f166}
      \strng{fullhash}{5afe3eb3246d0b46f32cdc5ff3e9d6b8}
      \strng{bibnamehash}{8b5c7065f4df4f81627df9460343f166}
      \strng{authorbibnamehash}{8b5c7065f4df4f81627df9460343f166}
      \strng{authornamehash}{8b5c7065f4df4f81627df9460343f166}
      \strng{authorfullhash}{5afe3eb3246d0b46f32cdc5ff3e9d6b8}
      \field{sortinit}{1}
      \field{sortinithash}{2174f786c6195e7fe2ee1c229b416e29}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{arXiv.org}
      \field{month}{6}
      \field{title}{{Generative Adversarial Networks}}
      \field{year}{2014}
      \verb{eprint}
      \verb 1406.2661
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Goodfellow et al. - 2014 - Generative Adversarial Networks.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1406.2661
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1406.2661
      \endverb
    \endentry
    \entry{simple_rnn}{book}{}
      \name{author}{2}{}{%
        {{hash=3db35867d3f3e41a78cd2e66e496b5ec}{%
           family={Cruse},
           familyi={C\bibinitperiod},
           given={Holk.},
           giveni={H\bibinitperiod}}}%
        {{hash=6a1f9821870611e7e1c6004fa344fa4c}{%
           family={Holk},
           familyi={H\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {G. Thieme Verlag}%
      }
      \strng{namehash}{a4f23ea46a9441612ffee6183ff57019}
      \strng{fullhash}{a4f23ea46a9441612ffee6183ff57019}
      \strng{bibnamehash}{a4f23ea46a9441612ffee6183ff57019}
      \strng{authorbibnamehash}{a4f23ea46a9441612ffee6183ff57019}
      \strng{authornamehash}{a4f23ea46a9441612ffee6183ff57019}
      \strng{authorfullhash}{a4f23ea46a9441612ffee6183ff57019}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{isbn}{0865776725}
      \field{title}{{Neural networks as cybernetic systems}}
      \field{year}{1996}
      \field{pages}{167}
      \range{pages}{1}
      \verb{urlraw}
      \verb https://dl.acm.org/citation.cfm?id=525023
      \endverb
      \verb{url}
      \verb https://dl.acm.org/citation.cfm?id=525023
      \endverb
    \endentry
    \entry{lstm_original}{article}{}
      \name{author}{2}{}{%
        {{hash=41b31e29fb2bdbf9f5c9c1b0d5b3e815}{%
           family={Hochreiter},
           familyi={H\bibinitperiod},
           given={Sepp},
           giveni={S\bibinitperiod}}}%
        {{hash=288bdbcfe1b91ad7484d7a24f74f99ed}{%
           family={Schmidhuber},
           familyi={S\bibinitperiod},
           given={J{\"{u}}rgen},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {MIT Press 238 Main St., Suite 500, Cambridge, MA 02142-1046 USA journals-info@mit.edu}%
      }
      \strng{namehash}{4c2e1e2e1ac91e1df9d4f7b85ebe39b4}
      \strng{fullhash}{4c2e1e2e1ac91e1df9d4f7b85ebe39b4}
      \strng{bibnamehash}{4c2e1e2e1ac91e1df9d4f7b85ebe39b4}
      \strng{authorbibnamehash}{4c2e1e2e1ac91e1df9d4f7b85ebe39b4}
      \strng{authornamehash}{4c2e1e2e1ac91e1df9d4f7b85ebe39b4}
      \strng{authorfullhash}{4c2e1e2e1ac91e1df9d4f7b85ebe39b4}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Learning to store information over extended time intervals by recurrent backpropagation takes a very long time, mostly because of insufficient, decaying error backflow. We briefly review Hochreiter's (1991) analysis of this problem, then address it by introducing a novel, efficient, gradient based method called long short-term memory (LSTM). Truncating the gradient where this does not do harm, LSTM can learn to bridge minimal time lags in excess of 1000 discrete-time steps by enforcing constant error flow through constant error carousels within special units. Multiplicative gate units learn to open and close access to the constant error flow. LSTM is local in space and time; its computational complexity per time step and weight is O. 1. Our experiments with artificial data involve local, distributed, real-valued, and noisy pattern representations. In comparisons with real-time recurrent learning, back propagation through time, recurrent cascade correlation, Elman nets, and neural sequence chunking, LSTM l...}
      \field{issn}{0899-7667}
      \field{journaltitle}{Neural Comput.}
      \field{month}{11}
      \field{number}{8}
      \field{title}{{Long Short-Term Memory}}
      \field{volume}{9}
      \field{year}{1997}
      \field{pages}{1735\bibrangedash 1780}
      \range{pages}{46}
      \verb{doi}
      \verb 10.1162/neco.1997.9.8.1735
      \endverb
      \verb{urlraw}
      \verb http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.8.1735
      \endverb
      \verb{url}
      \verb http://www.mitpressjournals.org/doi/10.1162/neco.1997.9.8.1735
      \endverb
    \endentry
    \entry{lstm_forget_gate}{article}{}
      \name{author}{3}{}{%
        {{hash=805aa8bd8070a9c87d87ba3588da7bab}{%
           family={Gers},
           familyi={G\bibinitperiod},
           given={Felix\bibnamedelima A.},
           giveni={F\bibinitperiod\bibinitdelim A\bibinitperiod}}}%
        {{hash=288bdbcfe1b91ad7484d7a24f74f99ed}{%
           family={Schmidhuber},
           familyi={S\bibinitperiod},
           given={J{\"{u}}rgen},
           giveni={J\bibinitperiod}}}%
        {{hash=bdd8ffd78b64a16f8c61071ba7af7225}{%
           family={Cummins},
           familyi={C\bibinitperiod},
           given={Fred},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{395eb5a6975d991cae175817c6027ac4}
      \strng{fullhash}{f90ec3965a97856f5e2b784e9481582a}
      \strng{bibnamehash}{f90ec3965a97856f5e2b784e9481582a}
      \strng{authorbibnamehash}{f90ec3965a97856f5e2b784e9481582a}
      \strng{authornamehash}{395eb5a6975d991cae175817c6027ac4}
      \strng{authorfullhash}{f90ec3965a97856f5e2b784e9481582a}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0899-7667}
      \field{journaltitle}{Neural Comput.}
      \field{month}{10}
      \field{number}{10}
      \field{title}{{Learning to Forget: Continual Prediction with LSTM}}
      \field{volume}{12}
      \field{year}{2000}
      \field{pages}{2451\bibrangedash 2471}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1162/089976600300015015
      \endverb
      \verb{urlraw}
      \verb http://www.mitpressjournals.org/doi/10.1162/089976600300015015
      \endverb
      \verb{url}
      \verb http://www.mitpressjournals.org/doi/10.1162/089976600300015015
      \endverb
    \endentry
    \entry{lstm_peephole}{inproceedings}{}
      \name{author}{2}{}{%
        {{hash=0a15ad4f29cebc11075310a285eb2d1f}{%
           family={Gers},
           familyi={G\bibinitperiod},
           given={F.A.},
           giveni={F\bibinitperiod}}}%
        {{hash=07e9fb186fd9976e6be82e64365dc308}{%
           family={Schmidhuber},
           familyi={S\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {IEEE}%
      }
      \strng{namehash}{ae8aabc261d5bec5b94dce66e6d86961}
      \strng{fullhash}{ae8aabc261d5bec5b94dce66e6d86961}
      \strng{bibnamehash}{ae8aabc261d5bec5b94dce66e6d86961}
      \strng{authorbibnamehash}{ae8aabc261d5bec5b94dce66e6d86961}
      \strng{authornamehash}{ae8aabc261d5bec5b94dce66e6d86961}
      \strng{authorfullhash}{ae8aabc261d5bec5b94dce66e6d86961}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Proc. IEEE-INNS-ENNS Int. Jt. Conf. Neural Networks. IJCNN 2000. Neural Comput. New Challenges Perspect. New Millenn.}
      \field{isbn}{0-7695-0619-4}
      \field{title}{{Recurrent nets that time and count}}
      \field{year}{2000}
      \field{pages}{189\bibrangedash 194 vol.3}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1109/IJCNN.2000.861302
      \endverb
      \verb{urlraw}
      \verb http://ieeexplore.ieee.org/document/861302/
      \endverb
      \verb{url}
      \verb http://ieeexplore.ieee.org/document/861302/
      \endverb
    \endentry
    \entry{gru}{article}{}
      \name{author}{7}{}{%
        {{hash=3da7501a79d9346572c7fd6e41b615df}{%
           family={Cho},
           familyi={C\bibinitperiod},
           given={Kyunghyun},
           giveni={K\bibinitperiod}}}%
        {{hash=d27fe3f9898ba01eeca28e3bd205f9ea}{%
           family={Merrienboer},
           familyi={M\bibinitperiod},
           given={Bart},
           giveni={B\bibinitperiod},
           prefix={van},
           prefixi={v\bibinitperiod}}}%
        {{hash=2adc0c92c308f233c731321d55efe58f}{%
           family={Gulcehre},
           familyi={G\bibinitperiod},
           given={Caglar},
           giveni={C\bibinitperiod}}}%
        {{hash=6d80adec79a13a33e73215c5f46f1605}{%
           family={Bahdanau},
           familyi={B\bibinitperiod},
           given={Dzmitry},
           giveni={D\bibinitperiod}}}%
        {{hash=6deedc795e51da1bc7fd6289ab321a48}{%
           family={Bougares},
           familyi={B\bibinitperiod},
           given={Fethi},
           giveni={F\bibinitperiod}}}%
        {{hash=449689e8c1ced50f608244e3a96fe6d3}{%
           family={Schwenk},
           familyi={S\bibinitperiod},
           given={Holger},
           giveni={H\bibinitperiod}}}%
        {{hash=40a8e4774982146adc2688546f54efb2}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Yoshua},
           giveni={Y\bibinitperiod}}}%
      }
      \strng{namehash}{9b1920db887fe0d658725c1e606b61f4}
      \strng{fullhash}{93de344d8644049cc7e61f1b9095d310}
      \strng{bibnamehash}{9b1920db887fe0d658725c1e606b61f4}
      \strng{authorbibnamehash}{9b1920db887fe0d658725c1e606b61f4}
      \strng{authornamehash}{9b1920db887fe0d658725c1e606b61f4}
      \strng{authorfullhash}{93de344d8644049cc7e61f1b9095d310}
      \field{sortinit}{2}
      \field{sortinithash}{cbff857e587bcb4635511624d773949e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this paper, we propose a novel neural network model called RNN Encoder-Decoder that consists of two recurrent neural networks (RNN). One RNN encodes a sequence of symbols into a fixed-length vector representation, and the other decodes the representation into another sequence of symbols. The encoder and decoder of the proposed model are jointly trained to maximize the conditional probability of a target sequence given a source sequence. The performance of a statistical machine translation system is empirically found to improve by using the conditional probabilities of phrase pairs computed by the RNN Encoder-Decoder as an additional feature in the existing log-linear model. Qualitatively, we show that the proposed model learns a semantically and syntactically meaningful representation of linguistic phrases.}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{title}{{Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation}}
      \field{year}{2014}
      \verb{eprint}
      \verb 1406.1078
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Cho et al. - 2014 - Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1406.1078
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1406.1078
      \endverb
    \endentry
    \entry{teacher-forcing}{article}{}
      \name{author}{4}{}{%
        {{hash=6d93a2b5e4e1f368f5ffe4344bfec8ef}{%
           family={Ranzato},
           familyi={R\bibinitperiod},
           given={Marc'Aurelio},
           giveni={M\bibinitperiod}}}%
        {{hash=83e9081b3be58a20d597b22b70648e30}{%
           family={Chopra},
           familyi={C\bibinitperiod},
           given={Sumit},
           giveni={S\bibinitperiod}}}%
        {{hash=d3ff0eff0a1d1258618c88f2ec57095f}{%
           family={Auli},
           familyi={A\bibinitperiod},
           given={Michael},
           giveni={M\bibinitperiod}}}%
        {{hash=e9fec85bbce1b087a6ebefe26e73f7bf}{%
           family={Zaremba},
           familyi={Z\bibinitperiod},
           given={Wojciech},
           giveni={W\bibinitperiod}}}%
      }
      \strng{namehash}{f5b5b34ccc096b5267b4ac2014ec8964}
      \strng{fullhash}{fdf93e0ccb0d3fcd4e44eaffc2323465}
      \strng{bibnamehash}{fdf93e0ccb0d3fcd4e44eaffc2323465}
      \strng{authorbibnamehash}{fdf93e0ccb0d3fcd4e44eaffc2323465}
      \strng{authornamehash}{f5b5b34ccc096b5267b4ac2014ec8964}
      \strng{authorfullhash}{fdf93e0ccb0d3fcd4e44eaffc2323465}
      \field{sortinit}{3}
      \field{sortinithash}{a4b52e5432884761f50fb9571273b93e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Many natural language processing applications use language models to generate text. These models are typically trained to predict the next word in a sequence, given the previous words and some context such as an image. However, at test time the model is expected to generate the entire sequence from scratch. This discrepancy makes generation brittle, as errors may accumulate along the way. We address this issue by proposing a novel sequence level training algorithm that directly optimizes the metric used at test time, such as BLEU or ROUGE. On three different tasks, our approach outperforms several strong baselines for greedy generation. The method is also competitive when these baselines employ beam search, while being several times faster.}
      \field{eprinttype}{arXiv}
      \field{month}{11}
      \field{title}{{Sequence Level Training with Recurrent Neural Networks}}
      \field{year}{2015}
      \verb{eprint}
      \verb 1511.06732
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Ranzato et al. - 2015 - Sequence Level Training with Recurrent Neural Networks.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1511.06732
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1511.06732
      \endverb
    \endentry
    \entry{scheduled-sampling}{article}{}
      \name{author}{4}{}{%
        {{hash=02404a92b0be3f52ec5ac08e41c13445}{%
           family={Bengio},
           familyi={B\bibinitperiod},
           given={Samy},
           giveni={S\bibinitperiod}}}%
        {{hash=494b568c5dc85ba8f3f409635f9c5f25}{%
           family={Vinyals},
           familyi={V\bibinitperiod},
           given={Oriol},
           giveni={O\bibinitperiod}}}%
        {{hash=5a9f30e0c0441d2aea255916ff375e8c}{%
           family={Jaitly},
           familyi={J\bibinitperiod},
           given={Navdeep},
           giveni={N\bibinitperiod}}}%
        {{hash=62efade83d70f0323fe248755e6c90c5}{%
           family={Shazeer},
           familyi={S\bibinitperiod},
           given={Noam},
           giveni={N\bibinitperiod}}}%
      }
      \strng{namehash}{a7107fc44d58e0d53178f67bb2ce15f8}
      \strng{fullhash}{408b3268fa483a5b87403a194fe84027}
      \strng{bibnamehash}{408b3268fa483a5b87403a194fe84027}
      \strng{authorbibnamehash}{408b3268fa483a5b87403a194fe84027}
      \strng{authornamehash}{a7107fc44d58e0d53178f67bb2ce15f8}
      \strng{authorfullhash}{408b3268fa483a5b87403a194fe84027}
      \field{sortinit}{3}
      \field{sortinithash}{a4b52e5432884761f50fb9571273b93e}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Recurrent Neural Networks can be trained to produce sequences of tokens given some input, as exemplified by recent results in machine translation and image captioning. The current approach to training them consists of maximizing the likelihood of each token in the sequence given the current (recurrent) state and the previous token. At inference, the unknown previous token is then replaced by a token generated by the model itself. This discrepancy between training and inference can yield errors that can accumulate quickly along the generated sequence. We propose a curriculum learning strategy to gently change the training process from a fully guided scheme using the true previous token, towards a less guided scheme which mostly uses the generated token instead. Experiments on several sequence prediction tasks show that this approach yields significant improvements. Moreover, it was used successfully in our winning entry to the MSCOCO image captioning challenge, 2015.}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{title}{{Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks}}
      \field{year}{2015}
      \verb{eprint}
      \verb 1506.03099
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Bengio et al. - 2015 - Scheduled Sampling for Sequence Prediction with Recurrent Neural Networks.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1506.03099
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1506.03099
      \endverb
    \endentry
    \entry{chembl22}{article}{}
      \name{author}{11}{}{%
        {{hash=ef090f0c6ff6138278103ca580237c79}{%
           family={Gaulton},
           familyi={G\bibinitperiod},
           given={Anna},
           giveni={A\bibinitperiod}}}%
        {{hash=487cc077788f608f931168464f0cc206}{%
           family={Bellis},
           familyi={B\bibinitperiod},
           given={Louisa\bibnamedelima J},
           giveni={L\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=15babd5b816886fb135a5e9122559972}{%
           family={Bento},
           familyi={B\bibinitperiod},
           given={A\bibnamedelima Patricia},
           giveni={A\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
        {{hash=f2013483442290f22126dc84887e4935}{%
           family={Chambers},
           familyi={C\bibinitperiod},
           given={Jon},
           giveni={J\bibinitperiod}}}%
        {{hash=48f427e0352f9d97eb37585a65f73622}{%
           family={Davies},
           familyi={D\bibinitperiod},
           given={Mark},
           giveni={M\bibinitperiod}}}%
        {{hash=26c46675e41f83087572952ccbdfe62c}{%
           family={Hersey},
           familyi={H\bibinitperiod},
           given={Anne},
           giveni={A\bibinitperiod}}}%
        {{hash=2f075c18cc8850e81a86667c17e24508}{%
           family={Light},
           familyi={L\bibinitperiod},
           given={Yvonne},
           giveni={Y\bibinitperiod}}}%
        {{hash=b02717f1abad23d3f3931a27cd38d61d}{%
           family={McGlinchey},
           familyi={M\bibinitperiod},
           given={Shaun},
           giveni={S\bibinitperiod}}}%
        {{hash=c3254bbe4a402d1593ad7b3c87ba417d}{%
           family={Michalovich},
           familyi={M\bibinitperiod},
           given={David},
           giveni={D\bibinitperiod}}}%
        {{hash=6c2de189b3311c216fbbd5bfb9f79020}{%
           family={Al-Lazikani},
           familyi={A\bibinithyphendelim L\bibinitperiod},
           given={Bissan},
           giveni={B\bibinitperiod}}}%
        {{hash=bc3575a95b639a6cb20d78a7f25db223}{%
           family={Overington},
           familyi={O\bibinitperiod},
           given={John\bibnamedelima P},
           giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Oxford University Press}%
      }
      \strng{namehash}{ff5ab39baf9badc17a3aa08562505392}
      \strng{fullhash}{faa37b4fe8ff6896edb8e8b87c78cfff}
      \strng{bibnamehash}{ff5ab39baf9badc17a3aa08562505392}
      \strng{authorbibnamehash}{ff5ab39baf9badc17a3aa08562505392}
      \strng{authornamehash}{ff5ab39baf9badc17a3aa08562505392}
      \strng{authorfullhash}{faa37b4fe8ff6896edb8e8b87c78cfff}
      \field{sortinit}{4}
      \field{sortinithash}{11cdaee3b18e01d77f3f428b13c1fc76}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{ChEMBL is an Open Data database containing binding, functional and ADMET information for a large number of drug-like bioactive compounds. These data are manually abstracted from the primary published literature on a regular basis, then further curated and standardized to maximize their quality and utility across a wide range of chemical biology and drug-discovery research problems. Currently, the database contains 5.4 million bioactivity measurements for more than 1 million compounds and 5200 protein targets. Access is available through a web-based interface, data downloads and web services at: https://www.ebi.ac.uk/chembldb.}
      \field{issn}{1362-4962}
      \field{journaltitle}{Nucleic Acids Res.}
      \field{month}{1}
      \field{number}{Database issue}
      \field{title}{{ChEMBL: a large-scale bioactivity database for drug discovery.}}
      \field{volume}{40}
      \field{year}{2012}
      \field{pages}{D1100\bibrangedash 7}
      \range{pages}{-1}
      \verb{doi}
      \verb 10.1093/nar/gkr777
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Gaulton et al. - 2012 - ChEMBL a large-scale bioactivity database for drug discovery.pdf:pdf;:Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Gaulton et al. - 2012 - ChEMBL a large-scale bioactivity database for drug discovery(2).pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://www.ncbi.nlm.nih.gov/pubmed/21948594 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3245175
      \endverb
      \verb{url}
      \verb http://www.ncbi.nlm.nih.gov/pubmed/21948594%20http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC3245175
      \endverb
    \endentry
    \entry{zinc12}{article}{}
      \name{author}{5}{}{%
        {{hash=88db176c547e9820bd1f9f18333fac66}{%
           family={Irwin},
           familyi={I\bibinitperiod},
           given={John\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
        {{hash=1d62ad764ccb3d47cb78bde11bbf44fc}{%
           family={Sterling},
           familyi={S\bibinitperiod},
           given={Teague},
           giveni={T\bibinitperiod}}}%
        {{hash=3e8d8f8dee91d7bece1721f99374f3cb}{%
           family={Mysinger},
           familyi={M\bibinitperiod},
           given={Michael\bibnamedelima M.},
           giveni={M\bibinitperiod\bibinitdelim M\bibinitperiod}}}%
        {{hash=12f87b2e9836c83914224f277a89d8ef}{%
           family={Bolstad},
           familyi={B\bibinitperiod},
           given={Erin\bibnamedelima S.},
           giveni={E\bibinitperiod\bibinitdelim S\bibinitperiod}}}%
        {{hash=9a5f905c00a22d8f55e9df092afd2868}{%
           family={Coleman},
           familyi={C\bibinitperiod},
           given={Ryan\bibnamedelima G.},
           giveni={R\bibinitperiod\bibinitdelim G\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {American Chemical Society}%
      }
      \strng{namehash}{92cf8146b8cb20192acab688d3a32288}
      \strng{fullhash}{f5fac5aabce57efd89d501a6532fbbe9}
      \strng{bibnamehash}{f5fac5aabce57efd89d501a6532fbbe9}
      \strng{authorbibnamehash}{f5fac5aabce57efd89d501a6532fbbe9}
      \strng{authornamehash}{92cf8146b8cb20192acab688d3a32288}
      \strng{authorfullhash}{f5fac5aabce57efd89d501a6532fbbe9}
      \field{sortinit}{4}
      \field{sortinithash}{11cdaee3b18e01d77f3f428b13c1fc76}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{ZINC is a free public resource for ligand discovery. The database contains over twenty million commercially available molecules in biologically relevant representations that may be downloaded in popular ready-to-dock formats and subsets. The Web site also enables searches by structure, biological activity, physical property, vendor, catalog number, name, and CAS number. Small custom subsets may be created, edited, shared, docked, downloaded, and conveyed to a vendor for purchase. The database is maintained and curated for a high purchasing success rate and is freely available at zinc.docking.org.}
      \field{issn}{1549-9596}
      \field{journaltitle}{J. Chem. Inf. Model.}
      \field{month}{7}
      \field{number}{7}
      \field{title}{{ZINC: A Free Tool to Discover Chemistry for Biology}}
      \field{volume}{52}
      \field{year}{2012}
      \field{pages}{1757\bibrangedash 1768}
      \range{pages}{12}
      \verb{doi}
      \verb 10.1021/ci3001277
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Irwin et al. - 2012 - ZINC A Free Tool to Discover Chemistry for Biology.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://pubs.acs.org/doi/10.1021/ci3001277
      \endverb
      \verb{url}
      \verb http://pubs.acs.org/doi/10.1021/ci3001277
      \endverb
    \endentry
    \entry{zinc15}{article}{}
      \name{author}{2}{}{%
        {{hash=1d62ad764ccb3d47cb78bde11bbf44fc}{%
           family={Sterling},
           familyi={S\bibinitperiod},
           given={Teague},
           giveni={T\bibinitperiod}}}%
        {{hash=88db176c547e9820bd1f9f18333fac66}{%
           family={Irwin},
           familyi={I\bibinitperiod},
           given={John\bibnamedelima J.},
           giveni={J\bibinitperiod\bibinitdelim J\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {American Chemical Society}%
      }
      \strng{namehash}{6ba92fd770e939a13c0da006b6dedc4c}
      \strng{fullhash}{6ba92fd770e939a13c0da006b6dedc4c}
      \strng{bibnamehash}{6ba92fd770e939a13c0da006b6dedc4c}
      \strng{authorbibnamehash}{6ba92fd770e939a13c0da006b6dedc4c}
      \strng{authornamehash}{6ba92fd770e939a13c0da006b6dedc4c}
      \strng{authorfullhash}{6ba92fd770e939a13c0da006b6dedc4c}
      \field{sortinit}{4}
      \field{sortinithash}{11cdaee3b18e01d77f3f428b13c1fc76}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Many questions about the biological activity and availability of small molecules remain inaccessible to investigators who could most benefit from their answers. To narrow the gap between chemoinformatics and biology, we have developed a suite of ligand annotation, purchasability, target, and biology association tools, incorporated into ZINC and meant for investigators who are not computer specialists. The new version contains over 120 million purchasable \textquotedblleft{}drug-like\textquotedblright{} compounds -- effectively all organic molecules that are for sale -- a quarter of which are available for immediate delivery. ZINC connects purchasable compounds to high-value ones such as metabolites, drugs, natural products, and annotated compounds from the literature. Compounds may be accessed by the genes for which they are annotated as well as the major and minor target classes to which those genes belong. It offers new analysis tools that are easy for nonspecialists yet with few limitations for experts. ZINC retains its original 3D roots -- ...}
      \field{issn}{1549-9596}
      \field{journaltitle}{J. Chem. Inf. Model.}
      \field{month}{11}
      \field{number}{11}
      \field{title}{{ZINC 15 -- Ligand Discovery for Everyone}}
      \field{volume}{55}
      \field{year}{2015}
      \field{pages}{2324\bibrangedash 2337}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1021/acs.jcim.5b00559
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Sterling, Irwin - 2015 - ZINC 15 -- Ligand Discovery for Everyone.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://pubs.acs.org/doi/10.1021/acs.jcim.5b00559
      \endverb
      \verb{url}
      \verb http://pubs.acs.org/doi/10.1021/acs.jcim.5b00559
      \endverb
    \endentry
    \entry{rdkit}{misc}{}
      \name{author}{1}{}{%
        {{hash=e601a7c55532ce4224a97a4252dbd0c1}{%
           family={Landrum},
           familyi={L\bibinitperiod},
           given={Greg},
           giveni={G\bibinitperiod}}}%
      }
      \strng{namehash}{e601a7c55532ce4224a97a4252dbd0c1}
      \strng{fullhash}{e601a7c55532ce4224a97a4252dbd0c1}
      \strng{bibnamehash}{e601a7c55532ce4224a97a4252dbd0c1}
      \strng{authorbibnamehash}{e601a7c55532ce4224a97a4252dbd0c1}
      \strng{authornamehash}{e601a7c55532ce4224a97a4252dbd0c1}
      \strng{authorfullhash}{e601a7c55532ce4224a97a4252dbd0c1}
      \field{sortinit}{4}
      \field{sortinithash}{11cdaee3b18e01d77f3f428b13c1fc76}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{RDKit: Open-source cheminformatics}}
      \field{urlday}{10}
      \field{urlmonth}{5}
      \field{urlyear}{2018}
      \field{urldateera}{ce}
      \verb{urlraw}
      \verb http://www.rdkit.org
      \endverb
      \verb{url}
      \verb http://www.rdkit.org
      \endverb
      \keyw{python}
    \endentry
    \entry{randomforest}{article}{}
      \name{author}{1}{}{%
        {{hash=132b7100417675d55d5d4d8b244f7a34}{%
           family={Breiman},
           familyi={B\bibinitperiod},
           given={Leo},
           giveni={L\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Kluwer Academic Publishers}%
      }
      \strng{namehash}{132b7100417675d55d5d4d8b244f7a34}
      \strng{fullhash}{132b7100417675d55d5d4d8b244f7a34}
      \strng{bibnamehash}{132b7100417675d55d5d4d8b244f7a34}
      \strng{authorbibnamehash}{132b7100417675d55d5d4d8b244f7a34}
      \strng{authornamehash}{132b7100417675d55d5d4d8b244f7a34}
      \strng{authorfullhash}{132b7100417675d55d5d4d8b244f7a34}
      \field{sortinit}{4}
      \field{sortinithash}{11cdaee3b18e01d77f3f428b13c1fc76}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{08856125}
      \field{journaltitle}{Mach. Learn.}
      \field{number}{1}
      \field{title}{{Random Forests}}
      \field{volume}{45}
      \field{year}{2001}
      \field{pages}{5\bibrangedash 32}
      \range{pages}{28}
      \verb{doi}
      \verb 10.1023/A:1010933404324
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Breiman - 2001 - Random Forests.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1023/A:1010933404324
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1023/A:1010933404324
      \endverb
    \endentry
    \entry{gan_techniques}{article}{}
      \name{author}{6}{}{%
        {{hash=e6f76e1a4d058df028530916774ad3a7}{%
           family={Salimans},
           familyi={S\bibinitperiod},
           given={Tim},
           giveni={T\bibinitperiod}}}%
        {{hash=5d2585c11210cf1d4512e6e0a03ec315}{%
           family={Goodfellow},
           familyi={G\bibinitperiod},
           given={Ian},
           giveni={I\bibinitperiod}}}%
        {{hash=e9fec85bbce1b087a6ebefe26e73f7bf}{%
           family={Zaremba},
           familyi={Z\bibinitperiod},
           given={Wojciech},
           giveni={W\bibinitperiod}}}%
        {{hash=ece7baf9b320c51ead8e24c1c6386dbf}{%
           family={Cheung},
           familyi={C\bibinitperiod},
           given={Vicki},
           giveni={V\bibinitperiod}}}%
        {{hash=a812c46caad94fc8701be37871f303ba}{%
           family={Radford},
           familyi={R\bibinitperiod},
           given={Alec},
           giveni={A\bibinitperiod}}}%
        {{hash=c6649d02b24225ca4c9012cee6c790de}{%
           family={Chen},
           familyi={C\bibinitperiod},
           given={Xi},
           giveni={X\bibinitperiod}}}%
      }
      \strng{namehash}{6e17054b06affd744a3a07dd8e481751}
      \strng{fullhash}{94aa80cb8b940c824d67773890ce0a03}
      \strng{bibnamehash}{6e17054b06affd744a3a07dd8e481751}
      \strng{authorbibnamehash}{6e17054b06affd744a3a07dd8e481751}
      \strng{authornamehash}{6e17054b06affd744a3a07dd8e481751}
      \strng{authorfullhash}{94aa80cb8b940c824d67773890ce0a03}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We present a variety of new architectural features and training procedures that we apply to the generative adversarial networks (GANs) framework. We focus on two applications of GANs: semi-supervised learning, and the generation of images that humans find visually realistic. Unlike most work on generative models, our primary goal is not to train a model that assigns high likelihood to test data, nor do we require the model to be able to learn well without using any labels. Using our new techniques, we achieve state-of-the-art results in semi-supervised classification on MNIST, CIFAR-10 and SVHN. The generated images are of high quality as confirmed by a visual Turing test: our model generates MNIST samples that humans cannot distinguish from real data, and CIFAR-10 samples that yield a human error rate of 21.3{\%}. We also present ImageNet samples with unprecedented resolution and show that our methods enable the model to learn recognizable features of ImageNet classes.}
      \field{eprinttype}{arXiv}
      \field{month}{6}
      \field{title}{{Improved Techniques for Training GANs}}
      \field{year}{2016}
      \verb{eprint}
      \verb 1606.03498
      \endverb
      \verb{file}
      \verb :Users/amane/Library/Application Support/Mendeley Desktop/Downloaded/Salimans et al. - 2016 - Improved Techniques for Training GANs.pdf:pdf
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1606.03498
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1606.03498
      \endverb
    \endentry
    \entry{Neyshabur2017}{article}{}
      \name{author}{3}{}{%
        {{hash=e5f9e207dc41c0bc364d3e1d7be37cf1}{%
           family={Neyshabur},
           familyi={N\bibinitperiod},
           given={Behnam},
           giveni={B\bibinitperiod}}}%
        {{hash=666205762228d3cb67197dabe1b1f6e6}{%
           family={Bhojanapalli},
           familyi={B\bibinitperiod},
           given={Srinadh},
           giveni={S\bibinitperiod}}}%
        {{hash=129dc8d5d42f5202cd5a23d1c5fa2ca3}{%
           family={Chakrabarti},
           familyi={C\bibinitperiod},
           given={Ayan},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{74b1355b2778d7ef09e52798d8dbe5c4}
      \strng{fullhash}{f36af799ee09326f98b6ee77d1aabb8f}
      \strng{bibnamehash}{f36af799ee09326f98b6ee77d1aabb8f}
      \strng{authorbibnamehash}{f36af799ee09326f98b6ee77d1aabb8f}
      \strng{authornamehash}{74b1355b2778d7ef09e52798d8dbe5c4}
      \strng{authorfullhash}{f36af799ee09326f98b6ee77d1aabb8f}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Training generative adversarial networks is unstable in high-dimensions as the true data distribution tends to be concentrated in a small fraction of the ambient space. The discriminator is then quickly able to classify nearly all generated samples as fake, leaving the generator without meaningful gradients and causing it to deteriorate after a point in training. In this work, we propose training a single generator simultaneously against an array of discriminators, each of which looks at a different random low-dimensional projection of the data. Individual discriminators, now provided with restricted views of the input, are unable to reject generated samples perfectly and continue to provide meaningful gradients to the generator throughout training. Meanwhile, the generator learns to produce samples consistent with the full data distribution to satisfy all discriminators simultaneously. We demonstrate the practical utility of this approach experimentally, and show that it is able to produce image samples with higher quality than traditional training with a single discriminator.}
      \field{eprinttype}{arXiv}
      \field{journaltitle}{arXiv.org}
      \field{month}{5}
      \field{title}{{Stabilizing GAN Training with Multiple Random Projections}}
      \field{year}{2017}
      \verb{eprint}
      \verb 1705.07831
      \endverb
      \verb{urlraw}
      \verb http://arxiv.org/abs/1705.07831
      \endverb
      \verb{url}
      \verb http://arxiv.org/abs/1705.07831
      \endverb
    \endentry
    \entry{pytorch}{article}{}
      \name{author}{10}{}{%
        {{hash=56bf0b340039cf8594436a624ff548a9}{%
           family={Paszke},
           familyi={P\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod}}}%
        {{hash=4ba5062e5919c814aceec188d54c01f2}{%
           family={Gross},
           familyi={G\bibinitperiod},
           given={Sam},
           giveni={S\bibinitperiod}}}%
        {{hash=8ef51a0906e47d2b4472c4e714ed598f}{%
           family={Chintala},
           familyi={C\bibinitperiod},
           given={Soumith},
           giveni={S\bibinitperiod}}}%
        {{hash=f897ed422c34d95af2e22778dfc2607e}{%
           family={Chanan},
           familyi={C\bibinitperiod},
           given={Gregory},
           giveni={G\bibinitperiod}}}%
        {{hash=b9e701339e56fd0b171145b08288a1b7}{%
           family={Yang},
           familyi={Y\bibinitperiod},
           given={Edward},
           giveni={E\bibinitperiod}}}%
        {{hash=3f9535be511fd2fa346093e63b8e61a0}{%
           family={DeVito},
           familyi={D\bibinitperiod},
           given={Zachary},
           giveni={Z\bibinitperiod}}}%
        {{hash=c40352c194e60a3ef458ee7e8685afb5}{%
           family={Lin},
           familyi={L\bibinitperiod},
           given={Zeming},
           giveni={Z\bibinitperiod}}}%
        {{hash=954cf7680b6ce14813973eccdca3c4bc}{%
           family={Desmaison},
           familyi={D\bibinitperiod},
           given={Alban},
           giveni={A\bibinitperiod}}}%
        {{hash=f65a80959d520337ae99a0798515036c}{%
           family={Antiga},
           familyi={A\bibinitperiod},
           given={Luca},
           giveni={L\bibinitperiod}}}%
        {{hash=b5815e1692fa2d0c1f44eecf509bd7c4}{%
           family={Lerer},
           familyi={L\bibinitperiod},
           given={Adam},
           giveni={A\bibinitperiod}}}%
      }
      \strng{namehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{fullhash}{8e924960ee7482ab2452016228f53660}
      \strng{bibnamehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{authorbibnamehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{authornamehash}{724e74fc18651eb78eb82fbcd1d9dfb1}
      \strng{authorfullhash}{8e924960ee7482ab2452016228f53660}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{Automatic differentiation in PyTorch}}
      \field{year}{2017}
    \endentry
    \entry{keras}{misc}{}
      \true{moreauthor}
      \true{morelabelname}
      \name{author}{1}{}{%
        {{hash=14134a39113404b1f80969c9ccc1f71e}{%
           family={Chollet},
           familyi={C\bibinitperiod},
           given={Fran{\c{c}}ois},
           giveni={F\bibinitperiod}}}%
      }
      \strng{namehash}{2f3cf4de7406c8a08275677188d056f8}
      \strng{fullhash}{2f3cf4de7406c8a08275677188d056f8}
      \strng{bibnamehash}{2f3cf4de7406c8a08275677188d056f8}
      \strng{authorbibnamehash}{2f3cf4de7406c8a08275677188d056f8}
      \strng{authornamehash}{2f3cf4de7406c8a08275677188d056f8}
      \strng{authorfullhash}{2f3cf4de7406c8a08275677188d056f8}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{{Keras}}
      \field{year}{2015}
      \verb{urlraw}
      \verb https://keras.io
      \endverb
      \verb{url}
      \verb https://keras.io
      \endverb
    \endentry
    \entry{scikit-learn}{article}{}
      \name{author}{16}{}{%
        {{hash=6e96fec0d63277626bb324bd28cdecb7}{%
           family={Pedregosa},
           familyi={P\bibinitperiod},
           given={F},
           giveni={F\bibinitperiod}}}%
        {{hash=b99c2df2144dc5ee09317a7833dea42d}{%
           family={Varoquaux},
           familyi={V\bibinitperiod},
           given={G},
           giveni={G\bibinitperiod}}}%
        {{hash=955f19cea89ae97bb7936078898e6255}{%
           family={Gramfort},
           familyi={G\bibinitperiod},
           given={A},
           giveni={A\bibinitperiod}}}%
        {{hash=2787869c9954c1d4e9891098995feb75}{%
           family={Michel},
           familyi={M\bibinitperiod},
           given={V},
           giveni={V\bibinitperiod}}}%
        {{hash=86d47ab9ca1a9dae108b4d4a0418c679}{%
           family={Thirion},
           familyi={T\bibinitperiod},
           given={B},
           giveni={B\bibinitperiod}}}%
        {{hash=d42f9e9cec95da1dad2232eac74982ab}{%
           family={Grisel},
           familyi={G\bibinitperiod},
           given={O},
           giveni={O\bibinitperiod}}}%
        {{hash=8bd8ef25258dd2311f92df23fe71ecf7}{%
           family={Blondel},
           familyi={B\bibinitperiod},
           given={M},
           giveni={M\bibinitperiod}}}%
        {{hash=a5ee41fa92b9e425806e1773853f1932}{%
           family={Prettenhofer},
           familyi={P\bibinitperiod},
           given={P},
           giveni={P\bibinitperiod}}}%
        {{hash=0c808557734e8929976d1f06f99c4ff2}{%
           family={Weiss},
           familyi={W\bibinitperiod},
           given={R},
           giveni={R\bibinitperiod}}}%
        {{hash=9662a6ea01596c6dd450817ccac81c4a}{%
           family={Dubourg},
           familyi={D\bibinitperiod},
           given={V},
           giveni={V\bibinitperiod}}}%
        {{hash=39e81a3e2193b954680a0ab847a0bb55}{%
           family={Vanderplas},
           familyi={V\bibinitperiod},
           given={J},
           giveni={J\bibinitperiod}}}%
        {{hash=14c4a498c032f77d0b83f86c710dd50e}{%
           family={Passos},
           familyi={P\bibinitperiod},
           given={A},
           giveni={A\bibinitperiod}}}%
        {{hash=dc075b18fb4710a1a37b258804c57efe}{%
           family={Cournapeau},
           familyi={C\bibinitperiod},
           given={D},
           giveni={D\bibinitperiod}}}%
        {{hash=67ec0e8add781665a43010c9559111e9}{%
           family={Brucher},
           familyi={B\bibinitperiod},
           given={M},
           giveni={M\bibinitperiod}}}%
        {{hash=dcb3918f09eb8785e6b212a907cc37cf}{%
           family={Perrot},
           familyi={P\bibinitperiod},
           given={M},
           giveni={M\bibinitperiod}}}%
        {{hash=ab20fcf381cd45daa82417c6fc595051}{%
           family={Duchesnay},
           familyi={D\bibinitperiod},
           given={E},
           giveni={E\bibinitperiod}}}%
      }
      \strng{namehash}{3a097aa3ebf2b8c2acf988341dde9710}
      \strng{fullhash}{7a67607c66e4af944b5f16461d6d0a87}
      \strng{bibnamehash}{3a097aa3ebf2b8c2acf988341dde9710}
      \strng{authorbibnamehash}{3a097aa3ebf2b8c2acf988341dde9710}
      \strng{authornamehash}{3a097aa3ebf2b8c2acf988341dde9710}
      \strng{authorfullhash}{7a67607c66e4af944b5f16461d6d0a87}
      \field{sortinit}{5}
      \field{sortinithash}{3c19c3776b658b3558e9e2e4840c01e2}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{journaltitle}{J. Mach. Learn. Res.}
      \field{title}{{Scikit-learn: Machine Learning in Python}}
      \field{volume}{12}
      \field{year}{2011}
      \field{pages}{2825\bibrangedash 2830}
      \range{pages}{6}
    \endentry
  \enddatalist
\endrefsection
\endinput

