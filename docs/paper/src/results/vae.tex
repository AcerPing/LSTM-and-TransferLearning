\section{VAEを用いた高精度な活性予測} \label{sec:result_vae}

本節ではVAEを適用した際の結果を示す。

VAEを利用して活性値の回帰を行ったあと、構造生成を行った。

\subsection{使用したアーキテクチャ}

\tbref{tb:vae_parameter_search}にVAEのアーキテクチャで検討したパラメータを示す。
Denseは通常の全結合層、Conv1Dは1次元の畳み込み層、GRU・LSTMはRNNの一種、
Reparametrization層は入力を平均$\mu$と対数分散$\log\sigma^2$に変換する層、
Softmaxは各文字の出力を確率に変換する層をそれぞれ表す。
\begin{table}[tbp]
    \centering
\caption{VAEで検討したパラメータ} \label{tb:vae_parameter_search}
\begin{tabular}{lll}\hline
& 項目 & パラメータ候補 \\\hline
層の種類 & Encoderの入力層 & Embedding, One-Hot Encoding \\
& Encoderの隠れ層 & LSTM, GRU, Conv1D \\
& Encoderの出力層 & Reparametrization \\
& Decoderの入力層 & Dense \\
& Decoderの隠れ層 & LSTM, GRU \\
& Decoderの出力層 & Softmax \\\hline
各層のパラメータ & Embeddingの次元数 & 8, 16, 32, 64 \\
& Denseの次元数 & 32, 64, 128, 256 \\
& LSTMの次元数 & 16, 32, 64, 128 \\
& GRUの次元数 & 16, 32, 64, 128 \\
& Conv1Dのチャネル数 & 8, 16, 32, 64 \\
& Conv1Dのフィルタサイズ & 5, 6, 7, 8, 9, 10 \\
& 活性化関数 & ReLU, SELU \\\hline
最適化 & バッチサイズ & 512 \\
& 最適化手法 & Adam \\
& 学習率 & 1e-3 \\\hline
\end{tabular}
\end{table}

\tbref{tb:vae_model_detail}に採用されたパラメータを示す。
パラメータ候補のうち、層の種類はそれぞれの中で全探索するグリッドサーチを行った。
層のパラメータについては、次元数とフィルタサイズ、活性化関数についてはそれぞれ全探索を、
フィルタサイズについては組み合わせが膨大になるため実験の途中からは先行研究\cite{Gomez-Bombarelli2016}と同様の
パラメータを利用した。
Conv1D層の活性化関数には学習が速く、かつ精度も向上したSELU\cite{selu}を採用した。
一方、Dense、GRUの各層には一般的な区分線形関数ReLUを採用した。
\begin{table}[tbp]
    \centering
    \caption{モデルのアーキテクチャ} \label{tb:vae_model_detail}
    \begin{tabular}{llclc}\hline
     & 層の種類 & 層数 & パラメータ & 活性化関数 \\\hline
     Encoder & Embedding & 1 & 次元数16 &--- \\
      & Conv1D & 3 & チャネル数32, フィルタサイズ$[9, 9, 10]$ & SELU \\
     & Dense & 2 & 次元数32 & ReLU \\ 
     & Reparametrization & --- &  1 & --- \\\hline
    Decoder & Dense & 1 & 次元数32 & ReLU \\
     & GRU & 3 & 次元数32 & ReLU \\
     & Dense & 1 & 次元数32 & ReLU \\
     & Dense & 1 & ---  & Softmax \\\hline
    \end{tabular}
\end{table}

\subsection{比較した手法}

\tbref{tb:vae_method}に比較した手法の概要を示す。
一般的な機械学習手法として、Morgan Fingerprintで特徴抽出をしてRandom Forest\cite{randomforest}でモデルを構築したもの（FP+RF）、
RDKit Descriptorで特徴抽出をしてRandom Forestでモデルを構築したもの（desc+RF）を使用した。
\begin{table}[tbp]
    \centering
    \caption{比較した手法} \label{tb:vae_method}
    \begin{tabular}{lll}\hline
    名称& 特徴抽出 & モデル \\\hline
    FP+RF & Morgan Fingerprint & Random Forest \\
    desc+RF & RDKit Descriptor & Random Forest \\
    提案手法(VAE) & VAE  & VAE \\\hline   
    \end{tabular}
\end{table}

Random Forest\cite{randomforest}は広く用いられている非線形回帰手法で、複数の回帰木のアンサンブルを行うことで良い予測精度を示すことが知られている。

Morgan FingerprintとRDKit DescriptorはいずれもオープンソースのケモインフォマティクスライブラリであるRDKit\cite{rdkit}で計算した。

5-foldクロスバリデーションの予測精度が最も高くなるハイパーパラメータを探索した結果、
Morgan Fingerprintは半径$2$、ビット数$512$を採用し、Random Forestの回帰木の数は$900$を採用した。

\subsection{結果と考察}

\subsubsection{予測精度の比較}

\tbref{tb:vae_prediction_result}に予測精度の比較結果を示す。
$\RR$は決定係数と呼ばれ、説明変数が目的変数をどれだけ説明しているかを表す指標である。
範囲は$[-\infty, 1]$を取り、$1$に近いほど予測精度が良いことを表す。
MAEは絶対予測誤差の平均であり、範囲は$[0, \infty]$を取る。
$0$に近いほど予測精度が良いことを示す。
添字の$\mathrm{val}$はクロスバリデーションの精度、$\mathrm{test}$はテストデータに対する精度を表す。
テストデータに対する予測精度を確認すると、既往手法に比べて提案手法ではいずれの評価指標においても良好な予測ができたことが分かった。
\begin{table}[tbp]
\centering
\caption{予測精度の比較}
\label{tb:vae_prediction_result}
\begin{tabular}{lrrrr}\hline
名称 & $\RR\val$ & $\MAE\val$ & $\RR\test$ & $\MAE\test$ \\\hline
FP+RF & $0.832$& $0.213$& $0.853$& $0.196$\\
desc+RF & $0.727$& $0.276$& $0.790$& $0.252$\\
提案手法(VAE) & $0.882$& $0.209$& $0.903$& $0.190$\\\hline
\end{tabular}
\end{table}

以上の結果は、教師付きデータが少ない状況下において提案手法が構造と活性値との関係性を良くモデリングできたことを示すものである。
\figref{fig:vae_yyplot}にテストデータに対する実測pKiと予測pKiの関係を示す。広い範囲において良好な予測ができていることが分かった。
これは、活性値情報のないChEMBL22のデータによってSMILESの文法が学習され、わずかな教師データでも活性値との関係を学習できたことによると考えられる。
\begin{figure}[tbp]
    \centering
    \includegraphics[width=0.7\columnwidth]{../resource/vae/yyplot.png}
    \caption{実測値と予測値の関係} \label{fig:vae_yyplot}
\end{figure}

\subsubsection{構造生成}

良好な予測ができたため、潜在変数のサンプリングによって構造生成を試みた。

\figref{fig:vae_carbon_chain}に構造生成の結果の一例を示した。
これらは構造生成結果を目視で確認し、特徴的と感じた生成構造である。
訓練データに用いた構造と比較して、炭素鎖を伸ばしただけのものや、末端原子を置換しただけのものが多く生成された。
これらの構造は構造式上は新規構造ではあるが、骨格に全く変化がないため、創薬を意識した際に有用とは言えない。
\begin{figure}[tbp]
    \begin{minipage}[b]{0.49\hsize}
    \centering
    \includegraphics[height=2.5cm]{../resource/vae/path2.png} 
    \end{minipage}
    \begin{minipage}[b]{0.49\hsize}    
    \centering
    \includegraphics[height=2.5cm]{../resource/vae/path6.png}
    \end{minipage}

    \begin{minipage}[b]{0.49\hsize}    
        \centering
        \includegraphics[height=2.5cm]{../resource/vae/path4.png}
        \subcaption{訓練データ}
    \end{minipage}
    \begin{minipage}[b]{0.49\hsize}    
        \centering
        \includegraphics[height=2.5cm]{../resource/vae/path8.png}
        \subcaption{生成構造}
    \end{minipage}
\caption{炭素鎖を伸ばしただけの生成構造} \label{fig:vae_carbon_chain}
\end{figure}

考えられる原因は2点存在する。

1点目はモデルがM1、M2の2段階からなるということである。
潜在変数から復元を行う過程では復元誤差が存在する。
復元を2段階にすると2段階分の復元誤差が乗るため、正しいSMILESが生成されにくくなる。
復元誤差が小さくなりやすい構造変換は単純な構造変換であるため、
炭素鎖の伸長や末端原子の置換といった単純な変換を施しただけの構造が多く生き残ったと考えられる。

2点目は活性を連続値で表現したことである。
活性の有無という2値分類での評価であれば、予測にはある程度幅があっても問題ない。
しかし、連続値として評価した場合は許容される誤差の範囲が狭くなってしまう。
活性値の予測を行う際は、誤差が小さくても構わない。
しかし、構造生成の場合はある程度誤差を許容しなければ十分に構造変化を行うことができないと考えられる。

これを受け、以降の実験では、活性の評価は有無の2値分類で行った。